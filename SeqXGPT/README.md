# Open-Source List

We list all the datasets, models, training and testing codes related to SeqXGPT here. For a more general understanding of SeqXGPT's objectives, performance, and contributions, please refer to the [SeqXGPT homepage](https://github.com/Jihuai-wpy/SeqXGPT/tree/main).

## Datasets

Each dataset contains six files. Within each dataset folder, based on the source of AI-generated sentences in the document, they are organized into different files. You can refer to the requirements of different tasks in the paper to arrange and merge the files. Below are SeqXGPT-Bench and two important evaluation datasets.

### SeqXGPT-Bench

A sentence-level AI-generated text (AIGT) detection dataset used for the study of fine-grained AIGT detection.

**data format:**

```python
{
    "text": "Media playback is unsupported on your device 21 June 2013 Last updated at 12:31 BST The Market Hall Cinema in Brynmawr used to be run by the local council but when it announced its funding would stop last month, work began to find a way to keep it going. Thanks to the efforts of a group of local volunteers, the cinema has been saved and reopened under a new community initiative. The group, called \"Brynmawr Foundation\", raised enough funds to take over the lease of the building and purchase new equipment. They plan to show a mix of classic and new films, as well as host events and live performances. The Market Hall Cinema has been an important part of the town's history since it first opened in 1894, and this new initiative ensures that it will continue to be a valuable resource for the community.", 
    "prompt_len": 254, 
    "label": "gpt3re"
}
```

​	**`text`** refers to an entire document.

​	**`prompt_len`** marks the boundary between the sentences generated by humans and those generated by AI. The first `prompt_len` characters of the input `text`, i.e., *text[:prompt\_len]*, are the sentences generated by humans, while the rest are generated by a particular language model.

​	**`label`** is the label for each sentence, and there are six types of labels in total: `gpt2`, `gptneo`, `gptj`, `llama`, `gpt3re`, `human`.

### Document-Level Detection Dataset

A dataset used to evaluate the performance of various methods in document-level AIGT detection.

**data format:**

```python
{
    "text": "in this paper we consider the possible existence of unstable axisymmetric modes in kerr space times , resulting from exponentially growing solutions of the teukolsky equation .  we describe a transformation that casts the radial equation that results upon separation of variables in the teukolsky equation , in the form of a schrdinger equation , and combine the properties of the solutions of this equations with some recent results on the asymptotic behaviour of spin weighted spheroidal harmonics to prove the existence of an infinite family of unstable modes .  thus we prove that the stationary region beyond a kerr black hole inner horizon is unstable under gravitational linear perturbations .  we also prove that kerr space - time with angular momentum larger than its square mass , which has a naked singularity , is unstable .", 
    "label": "human"
}
```

​	**`text`** refers to an entire document.

​	**`label`** is the label for the document, and there are six types of labels in total: `gpt2`, `gptneo`, `gptj`, `llama`, `gpt3re`, `human`.

### OOD Sentence-Level Detection Dataset

A dataset used to evaluate the performance of various methods on OOD data.

**data format** is the same as the data format of [SeqXGPT-Bench](#seqxgpt-bench).

## Inference Server

We use four open-source (L)LMs to construct the original features of our SeqXGPT and the contrastive features for Sniffer: GPT2-xl (1.5B), GPT-Neo (2.7B), GPT-J (6B) and LLaMA (7B). For each model, we set up an inference server specifically for extracting perplexity lists.

You can launch the inference server through `backend_api.py`. The startup command is as follows:

```bash
# --model: [gpt2, gptneo, gptj, llama, t5]

python backend_api.py --port 6006 --timeout 30000 --debug --model=gpt2 --gpu=0
```

## Feature Extraction

After successfully starting the related inference server, you can extract **the original features of SeqXGPT** using `gen_features.py`:

```bash
python ./dataset/gen_features.py --get_en_features --input_file input.jsonl --output_file output.jsonl
```

**It's worth noting that** you need to modify the inference server's URL in this file to the URL of the server you started.

You can extract **the contrastive features for Sniffer** using:

```bash
python ./dataset/gen_features.py --get_en_features --input_file input.jsonl --output_file output_1.jsonl
```

```bash
python ./dataset/gen_features.py --process_features --input_file output_1.jsonl --output_file output_2.jsonl
```

## Models

### SeqXGPT

We have provided the **complete code** for the model, dataloader, and train/test-related function under the `SeqXGPT` folder.

Before training and testing, please refer to the [Feature Extraction](#feature-extraction) section to extract relevant features, which will serve as the `--data_path`. The reference command is as follows:

```bash
# split train / test dataset and then train. You can adjust the train/test ratio using '--train_ratio'.
python ./Seq_train/train.py --gpu=0 --split_dataset

# train
python ./Seq_train/train.py --gpu=0

# test
python ./Seq_train/train.py --gpu=0 --do_test

# test document-level AIGT detection
python ./Seq_train/train.py --gpu=0 --do_test --test_content
```

### DetectGPT

We have provided the complete code under the `DetectGPT` folder to obtain the loss for the perturbed sentences (a total of 40) and the loss for the original sentences.

Specifically, if used for **sentence-level AIGT detection**, you **need to** process the documents in the original dataset into individual sentences. You can use the following code:

```python
import nltk
sent_separator = nltk.data.load('tokenizers/punkt/english.pickle')

# text is the document to be split into sentences
sents = sent_separator.tokenize(text)
```

### Sniffer

We refer to the [Sniffer GitHub](https://github.com/OpenLMLab/Sniffer) and modify the original Sniffer to obtain the sentence-level Sniffer. For the complete code, see the `Sniffer` folder.

### Sent-RoBERTa

We implement sentence-level AIGT detection with RoBERTa based on the sentence classification task. The complete model, dataloader, and training codes can be found in the `Sent-RoBERTa` folder. It's important to **note that**, before inputting, you also need to process the documents in the original dataset into individual sentences.

### Seq-RoBERTa

We implement sentence-level AIGT detection with RoBERTa based on the sequence labeling task. The complete model, dataloader, and training codes can be found in the `Seq-RoBERTa` folder.

## Requirements

A complete description of the environment settings is available in `requirements.txt`, including version information for all dependency libraries, to ensure that other researchers can replicate our experimental environment precisely.

## Citation

If you find SeqXGPT useful for your research and applications, please cite using the Bibtex:

```
@misc{wang2023seqxgpt,
      title={SeqXGPT: Sentence-Level AI-Generated Text Detection}, 
      author={Pengyu Wang and Linyang Li and Ke Ren and Botian Jiang and Dong Zhang and Xipeng Qiu},
      year={2023},
      eprint={2310.08903},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

